{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Model Demonstration\n",
    "\n",
    "This notebook demonstrates the core concept behind **Retrieval-Augmented Generation (RAG)**: **Vector Embeddings**.\n",
    "\n",
    "We will:\n",
    "1.  Load the project's embedding model.\n",
    "2.  Embed simple sentences to visualize how semantic meaning is captured in vector space.\n",
    "3.  Process the entire **Data Mining Textbook**, split it into chapters, and visualize how different topics cluster together in 3D space.\n",
    "\n",
    "**Note:** This notebook requires `scikit-learn`, `matplotlib`, and `pandas` to be installed in your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "We load necessary libraries and set up the project environment to access our shared utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path to import src modules\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from src.util.env_check import get_embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Embedding Model\n",
    "We use the helper function `get_embed_model` to load the model defined in your `.env` file (e.g., `qwen3-embedding` or OpenAI's `text-embedding-3-small`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = get_embed_model()\n",
    "print(f\"Loaded embedding model: {embedding_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple Sentence Demonstration\n",
    "To understand embeddings, let's start small. We define two groups of sentences:\n",
    "1.  **Animals/Nature**\n",
    "2.  **Computer Science/Data Mining**\n",
    "\n",
    "We expect the model to group semantically similar sentences together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    # Group A: Animals\n",
    "    \"The quick brown fox jumps over the dog.\",\n",
    "    \"A dog is a man's best friend.\",\n",
    "    \"The cat sleeps on the warm windowsill.\",\n",
    "    \"Wild wolves hunt in packs in the forest.\",\n",
    "    \n",
    "    # Group B: Data Mining\n",
    "    \"Data mining involves discovering patterns in large datasets.\",\n",
    "    \"Neural networks are a subset of machine learning algorithms.\",\n",
    "    \"Clustering algorithms group similar data points together.\",\n",
    "    \"Retrieval augmented generation uses vector databases.\"\n",
    "]\n",
    "\n",
    "labels = [\"Animal\"] * 4 + [\"Tech\"] * 4\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = embedding_model.embed_documents(sentences)\n",
    "embeddings_array = np.array(embeddings)\n",
    "\n",
    "print(f\"Generated embeddings shape: {embeddings_array.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization (PCA)\n",
    "Embeddings are high-dimensional vectors (often 768+ dimensions). We use **Principal Component Analysis (PCA)** to reduce them to 3 dimensions so we can plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "reduced_embeddings = pca.fit_transform(embeddings_array)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "colors = {'Animal': 'green', 'Tech': 'blue'}\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    x, y, z = reduced_embeddings[i]\n",
    "    label = labels[i]\n",
    "    ax.scatter(x, y, z, c=colors[label], s=100, label=label if i in [0, 4] else \"\")\n",
    "    ax.text(x, y, z, sentence[:20] + \"...\", fontsize=9)\n",
    "\n",
    "ax.set_title(\"3D Visualization of Sentence Embeddings\")\n",
    "ax.set_xlabel(\"PC1\")\n",
    "ax.set_ylabel(\"PC2\")\n",
    "ax.set_zlabel(\"PC3\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Textbook Analysis\n",
    "Now we apply this to the actual course material. We will:\n",
    "1.  Load the **Textbook PDF**.\n",
    "2.  Use the `contents.json` map to split it into **Chapters**.\n",
    "3.  Embed a sample of text chunks from each chapter.\n",
    "4.  Visualize if chapters cluster separately in vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Paths\n",
    "json_path = \"../data/processed/contents.json\"\n",
    "pdf_path = \"../data/raw/Textbook.pdf\"\n",
    "\n",
    "# Load Chapter Map\n",
    "with open(json_path, \"r\") as f:\n",
    "    chapters_json = json.load(f)\n",
    "\n",
    "# Load PDF Pages\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "pages = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(pages)} pages from the textbook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Chapters\n",
    "We use the logic from `advanced_ingest.py` to extract text by chapter boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAGE_OFFSET = 26  # Offset for PDF vs Book page numbers\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "chapter_chunks = []\n",
    "chapter_labels = []\n",
    "\n",
    "# We will process only the first 6 chapters for clarity in the plot\n",
    "target_chapters = chapters_json[:6]\n",
    "\n",
    "print(f\"Processing {len(target_chapters)} chapters...\")\n",
    "\n",
    "for chapter in target_chapters:\n",
    "    start_page = chapter[\"start_page\"]\n",
    "    end_page = chapter[\"end_page\"]\n",
    "    ch_title = chapter[\"title\"]\n",
    "    ch_num = chapter[\"chapter_number\"]\n",
    "    \n",
    "    # Calculate PDF indices\n",
    "    start_idx = start_page + PAGE_OFFSET - 1\n",
    "    if end_page is not None:\n",
    "        end_idx = end_page + PAGE_OFFSET - 1\n",
    "        current_pages = pages[start_idx : end_idx + 1]\n",
    "    else:\n",
    "        current_pages = pages[start_idx : ]\n",
    "        \n",
    "    # Merge text for the chapter\n",
    "    full_text = \"\\n\".join([p.page_content for p in current_pages])\n",
    "    \n",
    "    # Create a document and split it\n",
    "    doc = Document(page_content=full_text, metadata={\"chapter\": f\"Ch {ch_num}\"})\n",
    "    chunks = text_splitter.split_documents([doc])\n",
    "    \n",
    "    # Take a sample of chunks (e.g., first 15) to keep the plot readable\n",
    "    sample_chunks = chunks[:15]\n",
    "    \n",
    "    for chunk in sample_chunks:\n",
    "        # Inject context like in our advanced ingest strategy\n",
    "        contextualized_text = f\"Chapter {ch_num}: {ch_title}\\n{chunk.page_content}\"\n",
    "        chapter_chunks.append(contextualized_text)\n",
    "        chapter_labels.append(f\"Ch {ch_num}\")\n",
    "\n",
    "print(f\"Total chunks prepared for embedding: {len(chapter_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Chapter Embeddings\n",
    "This may take a minute depending on your hardware (local CPU vs GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_embeddings = embedding_model.embed_documents(chapter_chunks)\n",
    "book_embeddings_array = np.array(book_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Visualization of Chapters\n",
    "We plot the chunks in 3D space, coloring them by chapter. You should see distinct clusters corresponding to different topics (e.g., \"Data Preparation\" vs \"Clustering\" vs \"Classification\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "reduced_book = pca.fit_transform(book_embeddings_array)\n",
    "\n",
    "# Create DataFrame for easier plotting\n",
    "df = pd.DataFrame(reduced_book, columns=['x', 'y', 'z'])\n",
    "df['label'] = chapter_labels\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Color map\n",
    "unique_labels = sorted(list(set(chapter_labels)))\n",
    "colors = plt.cm.jet(np.linspace(0, 1, len(unique_labels)))\n",
    "color_map = dict(zip(unique_labels, colors))\n",
    "\n",
    "for label in unique_labels:\n",
    "    subset = df[df['label'] == label]\n",
    "    ax.scatter(subset['x'], subset['y'], subset['z'], c=[color_map[label]], label=label, s=40, alpha=0.7)\n",
    "\n",
    "ax.set_title(\"Semantic Clusters of Textbook Chapters\")\n",
    "ax.set_xlabel(\"PC1\")\n",
    "ax.set_ylabel(\"PC2\")\n",
    "ax.set_zlabel(\"PC3\")\n",
    "ax.legend(title=\"Chapter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The plot above demonstrates that **semantically related text clusters together** in vector space.\n",
    "\n",
    "- Chunks from the same chapter (e.g., \"Data Preparation\") appear close to each other.\n",
    "- Chunks from different topics are separated.\n",
    "\n",
    "This spatial property allows our RAG system to find relevant information by simply looking for the \"closest\" vectors to the user's question."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}